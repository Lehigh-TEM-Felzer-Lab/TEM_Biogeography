{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created by modifying version of xtran.cpp by Jared M Kodero\n",
    "# Check dependencies file for required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # setting ignore as a parameter\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mUsing c:\\Users\\jmkod\\OneDrive\\Desktop\\Lehigh University\\Research\\tem\\TEM_Biogeography\\xtran\\new_xtran\\xbatch.xml as input file\u001b[0m\n",
      "\u001b[94m1 file(s) to be processed\u001b[0m\n",
      "\u001b[94mFilter parameters to be applied: {'lat_min': 42.5, 'lat_max': 42.5, 'lon_min': None, 'lon_max': None, 'region': None, 'start_year': None, 'end_year': 2020}\u001b[0m\n",
      "\n",
      "\n",
      "Working on -> c:\\Users\\jmkod\\OneDrive\\Desktop\\Lehigh University\\Research\\tem\\TEM_Biogeography\\xtran\\new_xtran\\NCE.csv\n",
      "File 1 of 1 processed successfully.\n",
      "\u001b[92mProgram executed successfully! Check 'UNITS.INFO' for variable units and '.SUMMARY' for stats. Thank you!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define data columns for TEM output files\n",
    "var_cols = [\n",
    "    \"LON\",\n",
    "    \"LAT\",\n",
    "    \"VARIABLE\",\n",
    "    \"ICOHORT\",\n",
    "    \"STANDAGE\",\n",
    "    \"POTVEG\",\n",
    "    \"CURRENTVEG\",\n",
    "    \"SUBTYPE\",\n",
    "    \"CMNT\",\n",
    "    \"PSIPLUSC\",\n",
    "    \"QLCON\",\n",
    "    \"CAREA\",\n",
    "    \"SUBAREA\",\n",
    "    \"YEAR\",\n",
    "    \"TOTAL\",\n",
    "    \"MAX\",\n",
    "    \"AVE\",\n",
    "    \"MIN\",\n",
    "    \"JAN\",\n",
    "    \"FEB\",\n",
    "    \"MAR\",\n",
    "    \"APR\",\n",
    "    \"MAY\",\n",
    "    \"JUN\",\n",
    "    \"JUL\",\n",
    "    \"AUG\",\n",
    "    \"SEP\",\n",
    "    \"OCT\",\n",
    "    \"NOV\",\n",
    "    \"DEC\",\n",
    "    \"REGION\",\n",
    "]\n",
    "\n",
    "units_out_file = \"UNITS.INFO\"\n",
    "\n",
    "\n",
    "# Define PFT names based on TEM vegetation codes\n",
    "pft_description = {\n",
    "    1: \"Ice\",\n",
    "    4: \"Boreal Forest\",\n",
    "    5: \"Forested Boreal Wetlands\",\n",
    "    6: \"Boreal Woodlands\",\n",
    "    8: \"Mixed Temperate Forests\",\n",
    "    9: \"Temperate Coniferous Forests\",\n",
    "    10: \"Temperate Deciduous Forests\",\n",
    "    11: \"Temperate Forested Wetlands\",\n",
    "    12: \"Tall Grasslands\",\n",
    "    13: \"Short Grasslands\",\n",
    "    14: \"Tropical Savannas\",\n",
    "    15: \"Arid Shrublands\",\n",
    "    16: \"Tropical Evergreen Forests\",\n",
    "    17: \"Tropical Forested Wetlands\",\n",
    "    18: \"Tropical Deciduous Forests\",\n",
    "    19: \"Xeromorphic Forests and Woodlands\",\n",
    "    20: \"Tropical Forested Floodplains\",\n",
    "    21: \"Deserts\",\n",
    "    25: \"Temperate Forested Floodplains\",\n",
    "    27: \"Wet Savannas\",\n",
    "    28: \"Salt Marsh\",\n",
    "    29: \"Mangroves\",\n",
    "    30: \"Tidal Freshwater Marshes\",\n",
    "    31: \"Temperate Savannas\",\n",
    "    32: \"Reserved\",\n",
    "    33: \"Temperate Broadleaved Evergreen Forests\",\n",
    "    34: \"Reserved2\",\n",
    "    35: \"Mediterranean Shrublands\",\n",
    "    36: \"Reserved3\",\n",
    "    37: \"Reserved4\",\n",
    "    38: \"Reserved5\",\n",
    "    39: \"Reserved6\",\n",
    "    40: \"Reserved7\",\n",
    "    41: \"Reserved8\",\n",
    "    42: \"Reserved9\",\n",
    "    43: \"Reserved10\",\n",
    "    44: \"Reserved11\",\n",
    "    45: \"Reserved12\",\n",
    "    46: \"Suburban\",\n",
    "    47: \"Rodale Pasture\",\n",
    "    48: \"Turflawn\",\n",
    "    49: \"Vegetable Farm\",\n",
    "    50: \"Crops\",\n",
    "    51: \"Pasture\",\n",
    "    52: \"Maize\",\n",
    "    53: \"Wheat\",\n",
    "    54: \"Rice\",\n",
    "    55: \"Soybean\",\n",
    "    56: \"Potato\",\n",
    "    \"0000\": \"All Plant Functional Types\",\n",
    "    \"\": \"\",\n",
    "}\n",
    "\n",
    "\n",
    "# Define the function to process the TEM output files\n",
    "def process_file(input_filename, filter_params):\n",
    "    df = pd.read_csv(input_filename, names=var_cols)\n",
    "    df[\"VARIABLE\"] = df[\"VARIABLE\"].str.strip()\n",
    "    df[\"REGION\"] = df[\"REGION\"].str.strip()\n",
    "    df[\"YEAR\"] = df[\"YEAR\"].astype(int)\n",
    "    df[\"LAT\"] = df[\"LAT\"].round(1)\n",
    "    df[\"LON\"] = df[\"LON\"].round(1)\n",
    "\n",
    "    # Get the first part of the variable name\n",
    "    variable_parts = df[\"VARIABLE\"].unique()\n",
    "    variable_first_part = variable_parts[0]\n",
    "\n",
    "    # Define the stats output file name\n",
    "    stats_out_file = variable_first_part + \".SUMMARY\"\n",
    "\n",
    "    # Define the function to get units\n",
    "    def get_units(variable, column):\n",
    "        value = df[\"VARIABLE\"][0]\n",
    "        if value == \"CH4FLUX\" or value == \"CH4EMISS\" or value == \"CH4CNSMP\":\n",
    "            if column == \"MNBYAR\":\n",
    "                return \"mgC/m^2\"\n",
    "            elif column == \"TOTFORECOZONE\":\n",
    "                return \"(gX10^12)\"\n",
    "        elif value == \"VSTRUCTN\" or value == \"SOILORGN\" or value == \"VEGN\":\n",
    "            if column == \"MNBYAR\":\n",
    "                return \"gN/m^2\"\n",
    "            elif column == \"TOTFORECOZONE\":\n",
    "                return \"Tg\"\n",
    "        elif value in [\n",
    "            \"VSTOREN\",\n",
    "            \"AVAILN\",\n",
    "            \"NETNMIN\",\n",
    "            \"NLOST\",\n",
    "            \"NINPUT\",\n",
    "            \"VEGNUP\",\n",
    "            \"LTRN\",\n",
    "            \"MICRONUP\",\n",
    "            \"VNMOBIL\",\n",
    "            \"VNRESORB\",\n",
    "            \"VEGSUP\",\n",
    "            \"VEGLUP\",\n",
    "            \"N2OFLUX\",\n",
    "        ]:\n",
    "            if column == \"MNBYAR\":\n",
    "                return \"mgN/m^2\"\n",
    "            elif column == \"TOTFORECOZONE\":\n",
    "                return \"(gX10^9)\"\n",
    "        else:\n",
    "            if column == \"MNBYAR\":\n",
    "                return \"gC/m^2\"\n",
    "            elif column == \"TOTFORECOZONE\":\n",
    "                return \"(gX10^12)\"\n",
    "        if column == \"TOTCELLAREA\":\n",
    "            return \"m^2\"\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    # Define the columns to get units for\n",
    "    columns = [\"TOTCELLAREA\", \"TOTFORECOZONE\", \"MNBYAR\"]\n",
    "\n",
    "    # Create an empty DataFrame to store the results\n",
    "    df_units = pd.DataFrame(\n",
    "        columns=[\"VARIABLE\", \"TOTCELLAREA\", \"TOTFORECOZONE\", \"MNBYAR\", \"DATE\", \"TIME\"]\n",
    "    )\n",
    "\n",
    "    # get the current date and time\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%d %B %Y\")\n",
    "    time = now.strftime(\"%H:%M\")\n",
    "\n",
    "    # get unique variables in the dataframe\n",
    "    variables = df[\"VARIABLE\"].unique()\n",
    "\n",
    "    # loop through each variable and column\n",
    "    for variable in variables:\n",
    "        row = {\"VARIABLE\": variable, \"DATE\": date, \"TIME\": time}\n",
    "        for column in columns:\n",
    "            # get the units for each variable and column\n",
    "            units = get_units(variable, column)\n",
    "\n",
    "            # store the units in the row\n",
    "            row[column] = units\n",
    "\n",
    "        # append the row to the DataFrame\n",
    "        df_units = pd.concat(\n",
    "            [df_units, pd.DataFrame(row, index=[0])], ignore_index=True\n",
    "        )\n",
    "\n",
    "    # save the units to a CSV file\n",
    "    df_units.to_csv(units_out_file, index=False, header=False, mode=\"a\")\n",
    "\n",
    "    # Define the function to filter the dataframe\n",
    "    def filter_dataframe(df, filter_params):\n",
    "        if filter_params is not None:\n",
    "            filter_criteria = []\n",
    "            if filter_params.get(\"lat_min\") is not None:\n",
    "                try:\n",
    "                    lat_min = float(filter_params[\"lat_min\"])\n",
    "                    filter_criteria.append(f\"LAT >= {lat_min}\")\n",
    "                except ValueError:\n",
    "                    print(\n",
    "                        \"\\033[91m\"\n",
    "                        + \"Invalid value for lat_min. Must be a float.\"\n",
    "                        + \"\\033[0m\"\n",
    "                    )\n",
    "            if filter_params.get(\"lat_max\") is not None:\n",
    "                try:\n",
    "                    lat_max = float(filter_params[\"lat_max\"])\n",
    "                    filter_criteria.append(f\"LAT <= {lat_max}\")\n",
    "                except ValueError:\n",
    "                    print(\n",
    "                        \"\\033[91m\"\n",
    "                        + \"Invalid value for lat_max. Must be a float.\"\n",
    "                        + \"\\033[0m\"\n",
    "                    )\n",
    "            if filter_params.get(\"lon_min\") is not None:\n",
    "                try:\n",
    "                    lon_min = float(filter_params[\"lon_min\"])\n",
    "                    filter_criteria.append(f\"LON >= {lon_min}\")\n",
    "                except ValueError:\n",
    "                    print(\n",
    "                        \"\\033[91m\"\n",
    "                        + \"Invalid value for lon_min. Must be a float.\"\n",
    "                        + \"\\033[0m\"\n",
    "                    )\n",
    "            if filter_params.get(\"lon_max\") is not None:\n",
    "                try:\n",
    "                    lon_max = float(filter_params[\"lon_max\"])\n",
    "                    filter_criteria.append(f\"LON <= {lon_max}\")\n",
    "                except ValueError:\n",
    "                    print(\n",
    "                        \"\\033[91m\"\n",
    "                        + \"Invalid value for lon_max. Must be a float.\"\n",
    "                        + \"\\033[0m\"\n",
    "                    )\n",
    "            if filter_params.get(\"region\") is not None:\n",
    "                region = filter_params.get(\"region\")\n",
    "                filter_criteria.append(f\"REGION == '{region}'\")\n",
    "            if filter_params.get(\"start_year\") is not None:\n",
    "                try:\n",
    "                    start_year = int(filter_params[\"start_year\"])\n",
    "                    filter_criteria.append(f\"YEAR >= {start_year}\")\n",
    "                except ValueError:\n",
    "                    print(\n",
    "                        \"\\033[91m\"\n",
    "                        + \"Invalid value for start_year. Must be an integer.\"\n",
    "                        + \"\\033[0m\"\n",
    "                    )\n",
    "            if filter_params.get(\"end_year\") is not None:\n",
    "                try:\n",
    "                    end_year = int(filter_params[\"end_year\"])\n",
    "                    filter_criteria.append(f\"YEAR <= {end_year}\")\n",
    "                except ValueError:\n",
    "                    print(\n",
    "                        \"\\033[91m\"\n",
    "                        + \"Invalid value for end_year. Must be an integer.\"\n",
    "                        + \"\\033[0m\"\n",
    "                    )\n",
    "\n",
    "            if filter_criteria:\n",
    "                query_string = \" and \".join(filter_criteria)\n",
    "                try:\n",
    "                    df = df.query(query_string)\n",
    "                except ValueError:\n",
    "                    print(\n",
    "                        \"\\033[91m\"\n",
    "                        + \"Invalid filter criteria. Please check your parameters and try again.\"\n",
    "                        + \"\\033[0m\"\n",
    "                    )\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Filter the dataframe based on the filter parameters\n",
    "    df = filter_dataframe(df, filter_params)\n",
    "\n",
    "    # Function to calculate summary statistics for each POTVEG and REGION\n",
    "    def summary_stats(df, group_col):\n",
    "        summary = (\n",
    "            df.groupby([group_col, \"YEAR\", \"VARIABLE\"])\n",
    "            .agg(\n",
    "                {\n",
    "                    \"CAREA\": [\"count\", \"sum\"],\n",
    "                    \"TOTAL\": [\"max\", \"min\", \"mean\", \"std\"],\n",
    "                    \"AVE\": \"mean\",\n",
    "                }\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "        summary.columns = [\n",
    "            group_col,\n",
    "            \"YEAR\",\n",
    "            \"VARIABLE\",\n",
    "            \"NGRID\",\n",
    "            \"TOTCELLAREA\",\n",
    "            \"MXPRED\",\n",
    "            \"MNPRED\",\n",
    "            \"MNBYAR\",\n",
    "            \"STNDEV\",\n",
    "            \"MNTOTYR\",\n",
    "        ]\n",
    "        summary[\"TOTCELLAREA\"]\n",
    "        summary[\"TOTFORECOZONE\"] = (\n",
    "            summary[\"TOTCELLAREA\"] * summary[\"MNBYAR\"]\n",
    "        ) / 1000000\n",
    "        summary[\"SIMPMN\"] = summary[\"MNBYAR\"]\n",
    "\n",
    "        return summary\n",
    "\n",
    "    # Calculate summary statistics for POTVEG\n",
    "    summary_stats_potveg = summary_stats(df, \"POTVEG\")\n",
    "    summary_stats_potveg = summary_stats_potveg.round(2)\n",
    "    summary_stats_potveg[\"POTVEG\"] = summary_stats_potveg[\"POTVEG\"].round().astype(int)\n",
    "    summary_stats_potveg[\"YEAR\"] = summary_stats_potveg[\"YEAR\"].astype(int).astype(str)\n",
    "\n",
    "    # Calculate summary statistics for REGION\n",
    "    summary_stats_region = summary_stats(df, \"REGION\")\n",
    "    summary_stats_region = summary_stats_region.round(2)\n",
    "    summary_stats_region[\"POTVEG\"] = \"0000\"\n",
    "    summary_stats_region[\"YEAR\"] = summary_stats_region[\"YEAR\"].astype(int).astype(str)\n",
    "\n",
    "    # Concatenate the two summary statistics dataframes\n",
    "    summary_stats_final = pd.concat(\n",
    "        [\n",
    "            summary_stats_potveg,\n",
    "            pd.DataFrame(np.nan, index=[0], columns=summary_stats_potveg.columns),\n",
    "            summary_stats_region,\n",
    "        ]\n",
    "    )\n",
    "    summary_stats_final = summary_stats_final.round(2)\n",
    "\n",
    "    # Drop the REGION column\n",
    "    summary_stats_final = summary_stats_final.drop(\"REGION\", axis=1)\n",
    "\n",
    "    # Add a description column\n",
    "    summary_stats_final[\"DESCRIPTION\"] = summary_stats_final[\"POTVEG\"].map(\n",
    "        pft_description\n",
    "    )\n",
    "\n",
    "    # Reorder the columns\n",
    "    summary_stats_final = summary_stats_final.reindex(\n",
    "        columns=[\n",
    "            \"VARIABLE\",\n",
    "            \"POTVEG\",\n",
    "            \"DESCRIPTION\",\n",
    "            \"YEAR\",\n",
    "            \"NGRID\",\n",
    "            \"TOTFORECOZONE\",\n",
    "            \"MNBYAR\",\n",
    "            \"MXPRED\",\n",
    "            \"MNPRED\",\n",
    "            \"MNTOTYR\",\n",
    "            \"STNDEV\",\n",
    "            \"SIMPMN\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Save summary statistics to a CSV file\n",
    "    summary_stats_final.to_csv(stats_out_file, index=False)\n",
    "\n",
    "\n",
    "# Get the list of files to process, and optinal filters from the input XML file\n",
    "def get_file_list(input_path):\n",
    "    if input_path.endswith(\".xml\"):\n",
    "        tree = ET.parse(input_path)\n",
    "        root = tree.getroot()\n",
    "        file_list = []\n",
    "        for elem in root.findall(\"files/file\"):\n",
    "            file_path = elem.text\n",
    "            if file_path.startswith(\"./\") or file_path.startswith(\".\\\\\"):\n",
    "                file_path = os.path.abspath(os.path.join(os.getcwd(), file_path))\n",
    "            else:\n",
    "                file_path = os.path.abspath(file_path)\n",
    "            file_list.append(file_path)\n",
    "        filter_params = None\n",
    "        filter_params_elem = root.find(\"filter_params\")\n",
    "        if filter_params_elem is not None:\n",
    "            filter_params = {}\n",
    "            lat_min = filter_params_elem.findtext(\"lat_min\")\n",
    "            lat_max = filter_params_elem.findtext(\"lat_max\")\n",
    "            lon_min = filter_params_elem.findtext(\"lon_min\")\n",
    "            lon_max = filter_params_elem.findtext(\"lon_max\")\n",
    "            region = filter_params_elem.findtext(\"region\")\n",
    "            start_year = filter_params_elem.findtext(\"start_year\")\n",
    "            end_year = filter_params_elem.findtext(\"end_year\")\n",
    "            if (\n",
    "                lat_min.strip()\n",
    "                or lat_max.strip()\n",
    "                or lon_min.strip()\n",
    "                or lon_max.strip()\n",
    "                or region.strip()\n",
    "                or start_year.strip()\n",
    "                or end_year.strip()\n",
    "            ):\n",
    "                filter_params[\"lat_min\"] = (\n",
    "                    round(float(lat_min), 1) if lat_min.strip() else None\n",
    "                )\n",
    "                filter_params[\"lat_max\"] = (\n",
    "                    round(float(lat_max), 1) if lat_max.strip() else None\n",
    "                )\n",
    "                filter_params[\"lon_min\"] = (\n",
    "                    round(float(lon_min), 1) if lon_min.strip() else None\n",
    "                )\n",
    "                filter_params[\"lon_max\"] = (\n",
    "                    round(float(lon_max), 1) if lon_max.strip() else None\n",
    "                )\n",
    "                filter_params[\"region\"] = region.strip() if region.strip() else None\n",
    "                filter_params[\"start_year\"] = (\n",
    "                    int(start_year) if start_year.strip() else None\n",
    "                )\n",
    "                filter_params[\"end_year\"] = int(end_year) if end_year.strip() else None\n",
    "\n",
    "        else:\n",
    "            input_path = input_path.replace(\"./\", \"\").replace(\".\\\\\", \"\")\n",
    "            file_list = [os.path.abspath(input_path)]\n",
    "            filter_params = None\n",
    "\n",
    "    return file_list, filter_params\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Set a default terminal width\n",
    "    default_terminal_width = 100\n",
    "\n",
    "    # Try to get the terminal width, and if it fails, use the default width\n",
    "    try:\n",
    "        terminal_width = os.get_terminal_size().columns\n",
    "    except OSError:\n",
    "        terminal_width = default_terminal_width\n",
    "\n",
    "    # Print a line of dashes that fills the terminal width\n",
    "    print(\"-\" * terminal_width)\n",
    "\n",
    "    # open the file in write mode\n",
    "    with open(units_out_file, \"w\") as f:\n",
    "        # write the string to the file\n",
    "        f.write(\"VARIABLE, TOTCELLAREA, TOTFORECOZONE, MNBYAR, DATE, TIME\\n\")\n",
    "\n",
    "    error_occurred = False\n",
    "\n",
    "    try:\n",
    "        print(\"Running xtran to calculate summary statistics for the input file(s)\")\n",
    "        print(\"-\" * terminal_width)\n",
    "        input_path = input(\n",
    "            \"Please enter the filename, path or a XML file containing file paths and filter info: \"\n",
    "        )\n",
    "        input_path = os.path.join(\n",
    "            os.getcwd(), input_path\n",
    "        )  # Normalize the path for cross-platform compatibility\n",
    "        file_list, filter_params = get_file_list(input_path)\n",
    "        print(f\"\\033[94mUsing {input_path} as input file.\\033[0m\\n\")\n",
    "        print(f\"\\033[94mNumber of files to be processed: {len(file_list)}\\033[0m\")\n",
    "        print(f\"\\033[94mFilter parameters to be applied: \\033[0m \")\n",
    "        print(f\"\\033[94m\\tMinimum latitude: {filter_params['lat_min']}\\033[94m\")\n",
    "        print(f\"\\033[94m\\tMaximum latitude: {filter_params['lat_max']}\\033[94m\")\n",
    "        print(f\"\\033[94m\\tMinimum longitude: {filter_params['lon_min']}\\033[94m\")\n",
    "        print(f\"\\033[94m\\tMaximum longitude: {filter_params['lon_max']}\\033[94m\")\n",
    "        print(f\"\\033[94m\\tRegion: {filter_params['region']}\\033[94m\")\n",
    "        print(f\"\\033[94m\\tStart year: {filter_params['start_year']}\\033[94m\")\n",
    "        print(f\"\\033[94m\\tEnd year: {filter_params['end_year']}\\033[94m\\n\")\n",
    "\n",
    "        print(f\"\\033[94mProcessing files...\\033[0m\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\033[91m\" + f\"Error: XML file '{input_path}' not found.\" + \"\\033[0m\")\n",
    "        error_occurred = True\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        error_occurred = True\n",
    "\n",
    "    if not error_occurred:\n",
    "        for i, file_path in enumerate(file_list):\n",
    "            try:\n",
    "                process_file(file_path, filter_params)\n",
    "                print(\"\\033[33mWorking on -> {}\\033[0m\".format(file_path))\n",
    "                print(\n",
    "                    f\"\\033[92mFile {i+1} of {len(file_list)} processed successfully.\\033[0m\\n\"\n",
    "                )\n",
    "            except FileNotFoundError:\n",
    "                print(\"\\033[91m\" + f\"Error: File '{file_path}' not found.\" + \"\\033[0m\")\n",
    "                error_occurred = True\n",
    "                continue\n",
    "\n",
    "    if not error_occurred:\n",
    "        print(\"-\" * terminal_width)\n",
    "        print(\n",
    "            \"\\033[92mProgram executed successfully! Check 'UNITS.INFO' for variable units and '.SUMMARY' for stats. Thank you!\\033[0m\"\n",
    "        )\n",
    "        print(\"-\" * terminal_width)\n",
    "\n",
    "\n",
    "# Call the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d52fd5ec0d516378266d7ed095f105e90b725e9fa41f3690801f17e209f36a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
